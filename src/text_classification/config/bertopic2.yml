run:
  reduce_outliers: false

model:
  bertopic:
    min_topic_size: 15
    language: english
    top_n_words: 15
    nr_topics: auto
    calculate_probabilities: true

  sentence_transformer: all-MiniLM-L6-v2  # all-mpnet-base-v2  # all-mpnet-base-v2 # allenai-specter # all-MiniLM-L6-v2

  dimensionality_reduction:
    choice: umap
    params:
      umap:
        n_neighbors: 20
        n_components: 10
        min_dist: 0.0
        metric: cosine
        low_memory: false
        random_state: 654565

  clustering:
    choice: hdbscan
    params:
      hdbscan:
        min_cluster_size: 20
        #        max_cluster_size: 15
        min_samples: 15
        metric: euclidean
        #        algorithm: generic # comment to use default "best" one
        cluster_selection_method: eom # leaf # eom
        cluster_selection_epsilon: 0.0
        prediction_data: true # do not change this
        gen_min_span_tree: true
      kmeans:
        n_clusters: 20

  vectorizer:
    params:
      stop_words: english
      ngram_range: !!python/tuple [ 1, 2 ]
      #      max_df: 0.8
      #      min_df: 0.2
      max_features: 10000


  weighting:
    params:
      bm25_weighting: true
      reduce_frequent_words: true


  representation:
    choice: [ keybert, mmr ] # keybert, mmr, pos
    params:
      keybert:
        random_state: 17
        top_n_words: 15
      mmr:
        diversity: 0.7
        top_n_words: 15
      pos:
        model: en_core_web_lg
        top_n_words: 15
        pos_patterns: [
          [ { 'POS': 'ADJ' }, { 'POS': 'NOUN' } ],
          [ { 'POS': 'NOUN' } ],
          [ { 'POS': 'ADJ' } ]
        ]
